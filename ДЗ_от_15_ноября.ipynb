{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo2k0Bvqfr0OjLSs+T3x6G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamkamzer/pythonProject1/blob/main/%D0%94%D0%97_%D0%BE%D1%82_15_%D0%BD%D0%BE%D1%8F%D0%B1%D1%80%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Функция анализа тональности"
      ],
      "metadata": {
        "id": "gH8Om_xXDxBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN36R92zBLe3",
        "outputId": "8d775274-361e-4569-fc32-330753bc69e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "def analyze_sentiment(text):\n",
        "    positive_words = ['хороший', 'прекрасный', 'восхитительный']  # список позитивных слов\n",
        "    negative_words = ['плохой', 'ужасный', 'отвратительный']  # список негативных слов\n",
        "\n",
        "    # Подсчёт sentiment score\n",
        "    sentiment_score = sum(1 if word in positive_words else -1 if word in negative_words else 0 for word in text.lower().split())\n",
        "\n",
        "    # Определение результата\n",
        "    if sentiment_score > 0:\n",
        "        return \"positive\"\n",
        "    elif sentiment_score < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "text = \"Хороший фильм\"\n",
        "result = analyze_sentiment(text)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция оценки схожести двух предложений по коэффициенту Жаккара"
      ],
      "metadata": {
        "id": "Fsnl6E4cFnBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(sentence1, sentence2):\n",
        "    words1 = set(sentence1.lower().split())\n",
        "    words2 = set(sentence2.lower().split())\n",
        "\n",
        "    intersection = len(words1.intersection(words2))\n",
        "    union = len(words1) + len(words2) - intersection\n",
        "\n",
        "    similarity = intersection / union\n",
        "\n",
        "    return similarity\n",
        "\n",
        "sentence1 = \"Я люблю Python\"\n",
        "sentence2 = \"В свободное время я занимаюсь изучением Python\"\n",
        "\n",
        "similarity_index = jaccard_similarity(sentence1, sentence2)\n",
        "print(similarity_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqvOK18WD2Ag",
        "outputId": "8db23d36-78a2-4f4c-e31e-58f595a15265"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для создания словаря уникальных токенов с помощью gensim"
      ],
      "metadata": {
        "id": "F0zSqRGTM_BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "def create_token_dictionary(text):\n",
        "    tokenized_text = [word.lower().split() for word in text]\n",
        "    dictionary = corpora.Dictionary(tokenized_text)\n",
        "    return dictionary\n",
        "\n",
        "# Пример использования функции\n",
        "text = [\"Я люблю Python\", \"В свободное время я занимаюсь изучением Python\"]\n",
        "token_dictionary = create_token_dictionary(text)\n",
        "print(token_dictionary.token2id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYSa-0ICGTEh",
        "outputId": "db652dc1-f084-4873-e93c-2568783c0495"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'python': 0, 'люблю': 1, 'я': 2, 'в': 3, 'время': 4, 'занимаюсь': 5, 'изучением': 6, 'свободное': 7}\n"
          ]
        }
      ]
    }
  ]
}